# pinecone_integration.py
import time
import uuid
import asyncio
from typing import List, Dict
from pinecone import Pinecone, ServerlessSpec
from langchain_community.vectorstores import Pinecone as LangChainPinecone
from langchain_upstage.embeddings import UpstageEmbeddings
from sklearn.feature_extraction.text import TfidfVectorizer
from app.core.settings import settings
from app.utils.timestamp_utils import generate_timestamp_filter

# Pinecone ì¸ë±ìŠ¤ ì´ë¦„
INDEX_NAME = "my-rag-index"

# Pinecone í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
pc = Pinecone(api_key=settings.pinecone_api_key, environment=settings.pinecone_env)

# ê¸°ì¡´ ì¸ë±ìŠ¤ í™•ì¸ í›„ ì—†ìœ¼ë©´ ìƒì„±
existing_indexes = [index_info["name"] for index_info in pc.list_indexes()]
# ê¸°ì¡´ ì¸ë±ìŠ¤ í™•ì¸ í›„ ì—†ìœ¼ë©´ ìƒì„± (í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì§€ì› ì„¤ì • ì¶”ê°€)
if INDEX_NAME not in existing_indexes:
    pc.create_index(
        name=INDEX_NAME,
        dimension=4096,  # ë°€ì§‘ ë²¡í„° ì°¨ì›
        metric="dotproduct",  # âœ… í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì§€ì› (cosine â†’ dotproduct ë³€ê²½)
        spec=ServerlessSpec(cloud="aws", region="us-east-1"),
        deletion_protection="enabled"
    )
    while not pc.describe_index(INDEX_NAME).status["ready"]:
        time.sleep(1)

# Pinecone ì¸ë±ìŠ¤ ê°ì²´ ì—°ê²°
index = pc.Index(INDEX_NAME)

# Upstage Embeddings ê°ì²´ ìƒì„±
upstage_embeddings = UpstageEmbeddings(
    api_key=settings.upstage_api_key,
    model="embedding-query"
)

# Pinecone ë²¡í„° ì €ì¥ì†Œ ìƒì„±
vectorstore = LangChainPinecone.from_existing_index(
    index_name=INDEX_NAME,
    embedding=upstage_embeddings,
    text_key="session_id"
)

# Retriever ìƒì„±
retriever = vectorstore.as_retriever(
    search_type="mmr",
    search_kwargs={"k": 3}
)

# âœ… í¬ì†Œ ë²¡í„° ë³€í™˜ ìµœì í™” (scipy.sparse ì§ì ‘ ì ‘ê·¼)
def convert_tfidf_to_pinecone_format(tfidf_matrix, index: int) -> dict:
    """
    TF-IDF ë²¡í„°ë¥¼ Pinecone `sparse_values` í˜•ì‹ì— ë§ê²Œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜.
    - `numpy` ë³€í™˜ ì—†ì´ `scipy.sparse` ì§ì ‘ ì ‘ê·¼í•˜ì—¬ ì„±ëŠ¥ ìµœì í™”.

    Args:
        tfidf_matrix (scipy.sparse.csr_matrix): TF-IDF í¬ì†Œ í–‰ë ¬
        index (int): ë³€í™˜í•  ë¬¸ì„œì˜ ì¸ë±ìŠ¤

    Returns:
        dict: Pineconeì´ ìš”êµ¬í•˜ëŠ” `sparse_values` í˜•ì‹ (indices + values)
    """
    row = tfidf_matrix[index]  # íŠ¹ì • ë¬¸ì„œì˜ TF-IDF ë²¡í„°
    return {
        "indices": row.indices.tolist(),  # í¬ì†Œ í–‰ë ¬ ì¸ë±ìŠ¤
        "values": row.data.tolist()  # í•´ë‹¹ ì¸ë±ìŠ¤ì˜ TF-IDF ê°€ì¤‘ì¹˜
    }


# âœ… í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì„ ìœ„í•œ ë¬¸ì„œ ì €ì¥ (Pinecone ì—…ì„œíŠ¸)
async def upsert_documents(user_id: str, docs: List[str], metadatas: List[Dict] = None):
    """
    Pinecone ì¸ë±ìŠ¤ì— ë¬¸ì„œë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì—…ì„œíŠ¸í•˜ëŠ” í•¨ìˆ˜ (í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì§€ì›)
    - ë°€ì§‘ ë²¡í„° (Dense Vector) + í¬ì†Œ ë²¡í„° (Sparse Vector) í•¨ê»˜ ì €ì¥
    """
    if metadatas is None:
        metadatas = [{"content": doc} for doc in docs]

    # 1ï¸âƒ£ ë°€ì§‘ ë²¡í„° ìƒì„± (ë¹„ë™ê¸°)
    dense_embeddings = await asyncio.to_thread(upstage_embeddings.embed_documents, docs)

    # 2ï¸âƒ£ í¬ì†Œ ë²¡í„° ìƒì„± (TF-IDF) - ì§ì ‘ ì ‘ê·¼í•˜ì—¬ ì„±ëŠ¥ ìµœì í™”
    vectorizer = TfidfVectorizer()
    tfidf_matrix = vectorizer.fit_transform(docs)

    # 3ï¸âƒ£ Pineconeì— ì €ì¥í•  ë°ì´í„° êµ¬ì„±
    vectors = []
    for i, embedding in enumerate(dense_embeddings):
        sparse_vector = convert_tfidf_to_pinecone_format(tfidf_matrix, i)  # âœ… ìµœì í™”ëœ ë³€í™˜ ë°©ì‹ ì ìš©

        vectors.append({
            "id": str(uuid.uuid4()),
            "values": embedding,  # ë°€ì§‘ ë²¡í„°
            "sparse_values": sparse_vector,  # í¬ì†Œ ë²¡í„°
            "metadata": metadatas[i]  # ë¬¸ì„œ ë©”íƒ€ë°ì´í„°
        })

    # 4ï¸âƒ£ Pinecone ì—…ì„œíŠ¸ ì‹¤í–‰ (namespace: user_id ì ìš©)
    await asyncio.to_thread(index.upsert, vectors, namespace=user_id)

    return f"Upserted {len(docs)} documents into Pinecone (Hybrid Search Enabled, namespace: {user_id})"


# âœ… í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì ìš© (NER ê¸°ë°˜ í•„í„° + í¬ì†Œ ë²¡í„° ê²€ìƒ‰ ì¶”ê°€)
async def retrieve_documents(user_id: str, query: str, ner_info: dict, top_k: int = 3):
    """
    íŠ¹ì • ì‚¬ìš©ìì˜ namespaceì—ì„œ Pinecone í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ë¹„ë™ê¸° í•¨ìˆ˜
    - ë°€ì§‘ ë²¡í„° (Dense Vector) + í¬ì†Œ ë²¡í„° (Sparse Vector) ë™ì‹œ ê²€ìƒ‰
    - NER í•„í„° ë° ë‚ ì§œ í•„í„°ë§ ì ìš©
    """
    # ğŸ”¥ í•„í„° ì ìš© (NER ê¸°ë°˜ ê²€ìƒ‰)
    filter_query = {}
    if ner_info.get("keywords"):
        filter_query["keywords"] = {"$in": ner_info["keywords"]}
    if ner_info.get("events"):
        filter_query["events"] = {"$in": ner_info["events"]}
    if ner_info.get("persons"):
        filter_query["persons"] = {"$in": ner_info["persons"]}
    if ner_info.get("locations"):
        filter_query["locations"] = {"$in": ner_info["locations"]}

    # ğŸ”¥ ë‚ ì§œ í•„í„° ì ìš© (Timestamp ë³€í™˜ í›„ ì¶”ê°€)
    timestamp_filter = await generate_timestamp_filter(query)
    if timestamp_filter:
        filter_query.update(timestamp_filter)

    # ğŸ”¥ ì¿¼ë¦¬ ë²¡í„° ë³€í™˜ (ë°€ì§‘ ë²¡í„°)
    query_vector = await asyncio.to_thread(upstage_embeddings.embed_query, query)

    # ğŸ”¥ í¬ì†Œ ë²¡í„° ë³€í™˜ (TF-IDF) - ì§ì ‘ ì ‘ê·¼í•˜ì—¬ ì„±ëŠ¥ ìµœì í™”
    vectorizer = TfidfVectorizer()
    tfidf_matrix = vectorizer.fit_transform([query])
    sparse_vector = convert_tfidf_to_pinecone_format(tfidf_matrix, 0)  # âœ… ìµœì í™”ëœ ë³€í™˜ ë°©ì‹ ì ìš©

    # ğŸ”¥ Pinecone ê²€ìƒ‰ ì‹¤í–‰ (ë°€ì§‘ ë²¡í„° + í¬ì†Œ ë²¡í„° ì ìš©)
    response = await asyncio.to_thread(
        index.query,
        vector=query_vector,
        sparse_vector=sparse_vector,  # í¬ì†Œ ë²¡í„° ì¶”ê°€
        top_k=top_k,
        include_metadata=True,
        namespace=user_id,
        filter=filter_query if filter_query else {}
    )

    # ğŸ”¥ ê²€ìƒ‰ ê²°ê³¼ ë°˜í™˜
    results = [
        {
            "content": match["metadata"].get("content", "No content"),
            "metadata": match["metadata"]
        }
        for match in response.get("matches", [])
    ]

    return results
