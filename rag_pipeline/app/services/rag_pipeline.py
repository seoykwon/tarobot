# rag_pipeline.py
import asyncio
import datetime
import pytz
import json
from app.services.redis_utils import get_recent_history, save_message, get_summary_history, save_summary_history
from app.services.pinecone_integration import upsert_documents, retrieve_documents
from app.utils.fo_mini_api import call_4o_mini
from app.utils.prompt_generation import make_prompt_chat, make_prompt_ner
from app.utils.response_utils import response_generator  # âœ… Streaming ë¶„ë¦¬

# í•œêµ­ ì‹œê°„ëŒ€ ì ìš©
seoul_tz = pytz.timezone("Asia/Seoul")

# ğŸ”¥ [ê°œë°œìš©] ì„ì‹œ ì‚¬ìš©ì ë°ì´í„° (ë°±ì—”ë“œ ì—°ë™ ì „)
dummy_user_profile = {
    "user_id": "test_user_123",  # âœ… ê°œë°œìš© user_id
    "name": "í…ŒìŠ¤íŠ¸ ìœ ì €",  # ğŸ·ï¸ ì‚¬ìš©ì ì´ë¦„
    "birth_date": "1995-06-21",  # ğŸ‚ ìƒë…„ì›”ì¼
    "astro_sign": "Gemini",  # â™ˆ ë³„ìë¦¬
    "preferences": {  
        "preferred_reading_style": "detailed",  # ìƒì„¸í•œ ë¦¬ë”©ì„ ì›í•˜ëŠ”ì§€ ì—¬ë¶€
        "fav_tarot_cards": ["The High Priestess", "The Moon"]  # ì„ í˜¸í•˜ëŠ” íƒ€ë¡œ ì¹´ë“œ
    }
}

async def process_user_input(session_id: str, user_input: str):
    """
    ì‚¬ìš©ì ì…ë ¥ì„ ì²˜ë¦¬í•˜ëŠ” ë¹„ë™ê¸° í•¨ìˆ˜ (Redis ì €ì¥, ë¶„ì„, Pinecone ì—…ì„œíŠ¸ & ê²€ìƒ‰)
    """

    # âœ… user_idë¥¼ namespaceë¡œ í™œìš©
    user_id = dummy_user_profile["user_id"]  

    # ğŸ”¥ Redisì—ì„œ ìµœê·¼ ëŒ€í™” íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
    # recent_history = await get_recent_history(session_id)
    recent_history = await get_summary_history(session_id)

    # ğŸ”¥ ìƒˆë¡œìš´ ë©”ì‹œì§€ Redisì— ì €ì¥ (ìš”ì•½ ê°±ì‹ )
    await save_summary_history(session_id, user_input)
    save_task = asyncio.create_task(save_message(session_id, "user", user_input))
    
    # âœ… NER ë¶„ì„ (ê°œì²´ëª… ì¶”ì¶œ)
    ner_prompt = make_prompt_ner(user_input)
    ner_info_str = await call_4o_mini(ner_prompt, max_tokens=300)

    # âœ… NER ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ë³€í™˜
    try:
        ner_info = json.loads(ner_info_str)  
    except json.JSONDecodeError:
        ner_info = {}  

    # âœ… Pineconeì— ì—…ì„œíŠ¸í•  metadata êµ¬ì„±
    metadata = {
        "created_at": int(datetime.datetime.now(seoul_tz).timestamp()),
        "persons": ner_info.get("persons", []),  
        "locations": ner_info.get("locations", []),  
        "organizations": ner_info.get("organizations", []),  
        "events": ner_info.get("events", []),  
        "keywords": ner_info.get("keywords", [])  
    }

    # âœ… Pinecone namespace í™œìš©í•˜ë„ë¡ ë³€ê²½
    upsert_task = asyncio.create_task(upsert_documents(user_id, [user_input], [metadata]))
    retrieve_task = asyncio.create_task(retrieve_documents(user_id, user_input, ner_info, top_k=3))

    pine_results = await retrieve_task

    # âœ… ìµœì í™”ëœ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    context = prepare_context(recent_history, pine_results, ner_info)

    # ğŸ”¥ í•„ìˆ˜ ë¹„ë™ê¸° ì‘ì—… ì™„ë£Œ ë³´ì¥
    await asyncio.gather(save_task, upsert_task)

    return context

def prepare_context(recent_history, pine_results, ner_info):
    """
    ìµœì¢… ì»¨í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    """
    # âœ… Pinecone ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½
    pine_summary = []
    for doc in pine_results:
        metadata = doc.get("metadata", {})  # ğŸ”¥ `metadata`ê°€ ì—†ì„ ê²½ìš° ë¹ˆ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜
        pine_summary.append(f"- {metadata.get('summary', 'ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ')}")

    pine_summary_text = "\n".join(pine_summary) if pine_summary else "ê´€ë ¨ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

    # âœ… NER ì •ë³´ ì •ë¦¬
    ner_text = "\n".join([f"- {key}: {', '.join(value) if value else 'ì—†ìŒ'}" for key, value in ner_info.items()])

    # âœ… ìµœì í™”ëœ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    context = f"""
[ìµœê·¼ ëŒ€í™” ê¸°ë¡]:
{recent_history}

[Pinecone ê²€ìƒ‰ ìš”ì•½]: 
{pine_results}

[NER ì •ë³´]:
{ner_text}
    """

    return context.strip()  # âœ… ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°

async def rag_pipeline(session_id: str, user_input: str, stream: bool = False):
    """
    ë¹„ë™ê¸° ìµœì í™”ëœ RAG ê¸°ë°˜ ì±—ë´‡ íŒŒì´í”„ë¼ì¸ (Streaming ì§€ì›)
    """
    context = await process_user_input(session_id, user_input)

    if stream:
        return response_generator(session_id, user_input, context)

    chat_prompt = make_prompt_chat(context, user_input)
    print(chat_prompt)
    llm_answer = await call_4o_mini(chat_prompt, max_tokens=256, stream=False)

    save_response_task = asyncio.create_task(save_message(session_id, "assistant", llm_answer))

    # ğŸ”¥ ì±—ë´‡ ì‘ë‹µ ì €ì¥ ì™„ë£Œ ë³´ì¥
    await save_response_task

    return llm_answer
