# rag_pipeline.py
import asyncio
import datetime
import pytz
import json
from app.services.redis_utils import save_message, get_summary_history, save_summary_history
from app.services.pinecone_integration import upsert_documents, retrieve_documents
from app.utils.fo_mini_api import call_4o_mini
from app.utils.prompt_generation import make_prompt_chat, make_prompt_ner
from app.utils.response_utils import response_generator  # âœ… Streaming ë¶„ë¦¬

# ğŸ”¥ [ê°œë°œìš©] ì„ì‹œ ì‚¬ìš©ì ë°ì´í„° (ë°±ì—”ë“œ ì—°ë™ ì „)
dummy_user_profile = {
    "user_id": "test_user_123",  # âœ… ê°œë°œìš© user_id
    "name": "í…ŒìŠ¤íŠ¸ ìœ ì €",  # ğŸ·ï¸ ì‚¬ìš©ì ì´ë¦„
    "birth_date": "1995-06-21",  # ğŸ‚ ìƒë…„ì›”ì¼
    "astro_sign": "Gemini",  # â™ˆ ë³„ìë¦¬
    "preferences": {  
        "preferred_reading_style": "detailed",  # ìƒì„¸í•œ ë¦¬ë”©ì„ ì›í•˜ëŠ”ì§€ ì—¬ë¶€
        "fav_tarot_cards": ["The High Priestess", "The Moon"]  # ì„ í˜¸í•˜ëŠ” íƒ€ë¡œ ì¹´ë“œ
    }
}

async def process_user_input(session_id: str, user_input: str):
    """
    ì‚¬ìš©ì ì…ë ¥ì„ ì²˜ë¦¬í•˜ëŠ” ë¹„ë™ê¸° í•¨ìˆ˜ (Redis ì €ì¥, ë¶„ì„, Pinecone ì—…ì„œíŠ¸ & ê²€ìƒ‰)
    """
    try:
        print("ğŸŸ¢ process_user_input ì‹œì‘")  # âœ… ë¡œê·¸ ì¶”ê°€
        user_id = dummy_user_profile["user_id"]

        recent_history = await get_summary_history(session_id)
        await save_summary_history(session_id, user_input)
        save_task = asyncio.create_task(save_message(session_id, "user", user_input))

        ner_prompt = make_prompt_ner(user_input)
        keywords_str = await call_4o_mini(ner_prompt, max_tokens=300)

        try:
            keywords_dict = json.loads(keywords_str)
            keywords = keywords_dict.get("keywords", [])
        except json.JSONDecodeError:
            keywords = []

        print(f'ğŸ“Œ after_parsing: {keywords}')  # âœ… ë¡œê·¸ ì¶”ê°€

        retrieve_task = asyncio.create_task(retrieve_documents(user_id, user_input, keywords, top_k=3))

        pine_results = await retrieve_task
        print(f"ğŸ“Œ Pinecone ê²€ìƒ‰ ê²°ê³¼: {pine_results}")  # âœ… ë¡œê·¸ ì¶”ê°€

        context = prepare_context(recent_history, pine_results, keywords)
        await asyncio.gather(save_task)

        print("ğŸŸ£ process_user_input ì™„ë£Œ")  # âœ… ë¡œê·¸ ì¶”ê°€
        return context, keywords, user_id

    except Exception as e:
        print(f"âŒ process_user_input ì‹¤íŒ¨: {e}")  # âœ… ì˜ˆì™¸ ì¶œë ¥
        return None, None, None  # ì˜ˆì™¸ ë°œìƒ ì‹œ None ë°˜í™˜

def prepare_context(recent_history, pine_results, keywords):
    """
    ìµœì¢… ì»¨í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    """
    # âœ… Pinecone ê²€ìƒ‰ ê²°ê³¼ì—ì„œ content íŒŒì‹±
    pine_content = []
    for doc in pine_results:
        metadata = doc.get("metadata", {})  # ğŸ”¥ `metadata`ê°€ ì—†ì„ ê²½ìš° ë¹ˆ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜
        pine_content.append(f"- user_input : {metadata.get('user_input', 'ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ')}")
        pine_content.append(f"- response : {metadata.get('response', 'ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ')}")

    pine_content_text = "\n".join(pine_content) if pine_content else "ê´€ë ¨ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

    # âœ… NER ì •ë³´ ì •ë¦¬
    keywords = "\n".join(keywords)

    # âœ… ìµœì í™”ëœ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    context = f"""
            [ìµœê·¼ ëŒ€í™” ê¸°ë¡]:
            {recent_history}

            [Pinecone ê²€ìƒ‰ ìš”ì•½]: 
            {pine_content_text}

            [NER ì •ë³´]:
            {keywords}
            """

    return context.strip()  # âœ… ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°

async def rag_pipeline(session_id: str, user_input: str, stream: bool = False):
    """
    ë¹„ë™ê¸° ìµœì í™”ëœ RAG ê¸°ë°˜ ì±—ë´‡ íŒŒì´í”„ë¼ì¸ (Streaming ì§€ì›)
    """
    print("ğŸŸ¢ rag_pipeline ì‹œì‘")  # âœ… ë¡œê·¸ ì¶”ê°€
    # ì—…ì„œíŠ¸ë¥¼ ìœ„í•´ keywordsì™€ user_idë„ ë¦¬í„´ ë°›ê¸°
    context, keywords, user_id = await process_user_input(session_id, user_input)

    if stream:
        print("ğŸŸ¡ Streaming ëª¨ë“œë¡œ ì‹¤í–‰")  # âœ… ë¡œê·¸ ì¶”ê°€
        return response_generator(session_id, user_input, context)

    chat_prompt = make_prompt_chat(context, user_input)
    print(f"ğŸ“Œ ìƒì„±ëœ Chat Prompt: {chat_prompt}")  # âœ… ë¡œê·¸ ì¶”ê°€
    llm_answer = await call_4o_mini(chat_prompt, max_tokens=256, stream=False)
    print(f"ğŸŸ£ LLM ì‘ë‹µ ìƒì„± ì™„ë£Œ: {llm_answer}")  # âœ… ë¡œê·¸ ì¶”ê°€

    # âœ… Pineconeì— ì—…ì„œíŠ¸í•  metadata êµ¬ì„±
    metadata = {
        "created_at": int(datetime.datetime.now(pytz.timezone("Asia/Seoul")).timestamp()),
        "keywords": keywords if keywords else ["(ì—†ìŒ)"],  # ë¹ˆ ë°°ì—´ ë°©ì§€
        "user_input" : user_input,
        "response" : llm_answer
    }

    # Pinecone ì—…ì„œíŠ¸
    print(f"ğŸ”¹ Pinecone ì—…ì„œíŠ¸ ë°ì´í„°: {metadata}")  # ë””ë²„ê¹…ìš© ë¡œê·¸
    upsert_task = asyncio.create_task(upsert_documents(user_id, [user_input], [metadata]))

    # âœ… ì—…ì„œíŠ¸ ì‘ë‹µ í™•ì¸
    print(f"âœ… Pinecone ì—…ì„œíŠ¸ ê²°ê³¼: {upsert_task}")
    # redis ì €ì¥
    save_response_task = asyncio.create_task(save_message(session_id, "assistant", llm_answer))
    
    # ğŸ”¥ í•„ìˆ˜ ë¹„ë™ê¸° ì‘ì—… ì™„ë£Œ ë³´ì¥
    await asyncio.gather(save_response_task, upsert_task)
    print("ğŸ¯ ëª¨ë“  ë¹„ë™ê¸° ì‘ì—… ì™„ë£Œ")  # âœ… ë¡œê·¸ ì¶”ê°€

    return llm_answer
