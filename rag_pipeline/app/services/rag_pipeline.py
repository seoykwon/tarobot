# rag_pipeline.py
import asyncio
import json
from app.services.redis_utils import get_recent_history, save_message, get_summary_history, save_summary_history
from app.services.pinecone_integration import upsert_documents, retrieve_documents
from app.utils.fo_mini_api import call_4o_mini, make_prompt_chat, make_prompt_ner
from app.utils.response_utils import response_generator  # âœ… Streaming ë¶„ë¦¬

async def process_user_input(session_id: str, user_input: str):
    """
    ì‚¬ìš©ì ì…ë ¥ì„ ì²˜ë¦¬í•˜ëŠ” ë¹„ë™ê¸° í•¨ìˆ˜ (Redis ì €ì¥, NER ë¶„ì„, Pinecone ì—…ì„œíŠ¸ & ê²€ìƒ‰)
    """
    # recent_history = await get_recent_history(session_id)
    recent_summary = await get_summary_history(session_id)

    # ìƒˆë¡œìš´ ë©”ì‹œì§€ Redisì— ì €ì¥ (ìš”ì•½ ê°±ì‹ )
    asyncio.create_task(save_summary_history(session_id, user_input))

    save_task = asyncio.create_task(save_message(session_id, "user", user_input))

    # âœ… NER ë¶„ì„ ìˆ˜í–‰ (NERë§Œ ì‹¤í–‰)
    ner_prompt = make_prompt_ner(user_input)
    ner_response = await call_4o_mini(ner_prompt, max_tokens=300, stream=False)

    try:
        ner_info = json.loads(ner_response)
    except json.JSONDecodeError:
        ner_info = {
            "persons": [], "dates": [], "locations": [],
            "organizations": [], "events": [], "keywords": []
        }

    # Pineconeì— ì—…ì„œíŠ¸í•  metadata êµ¬ì„±
    metadata = {
        "session_id": session_id,
        "persons": ner_info.get("persons", []),
        "dates": ner_info.get("dates", []),
        "locations": ner_info.get("locations", []),
        "organizations": ner_info.get("organizations", []),
        "events": ner_info.get("events", []),
        "keywords": ner_info.get("keywords", [])
    }

    upsert_task = asyncio.create_task(upsert_documents([user_input], [metadata]))
    retrieve_task = asyncio.create_task(retrieve_documents(user_input, top_k=3))

    pine_results = await retrieve_task

    # âœ… ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (ê°ì • ë¶„ì„ ì œê±°)
    context = prepare_context(recent_summary, pine_results, ner_info)

    # í•„ìˆ˜ ë¹„ë™ê¸° ì‘ì—… ì™„ë£Œ ë³´ì¥
    await asyncio.gather(save_task, upsert_task)

    return context

def prepare_context(recent_history, pine_results, ner_info):
    """
    ìµœì¢… ì»¨í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ (NER ê¸°ë°˜ìœ¼ë¡œ êµ¬ì„±)
    """
    # âœ… Pinecone ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½
    pine_summary = []
    for doc in pine_results:
        metadata = doc["metadata"]
        pine_summary.append(f"- ê´€ë ¨ í‚¤ì›Œë“œ: {', '.join(metadata.get('keywords', []))}")

    pine_summary_text = "\n".join(pine_summary) if pine_summary else "ê´€ë ¨ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

    # NER ì •ë³´ ì •ë¦¬
    ner_text = ""
    for key, value in ner_info.items():
        formatted_key = key  # ì¸ë¬¼, ì¥ì†Œ, ì¡°ì§, ì´ë²¤íŠ¸ ë“±
        if value:
            ner_text += f"- {formatted_key}: {', '.join(value)}\n"
        else:
            ner_text += f"- {formatted_key}: ì—†ìŒ\n"

    # âœ… ê°ì • ë¶„ì„ ë° ìš”ì•½ ì œê±°, ìµœì‹  NER ì •ë³´ë§Œ í™œìš©
    context = f"""
[ìµœê·¼ ëŒ€í™” ê¸°ë¡]:
{recent_history}

[Pinecone ê²€ìƒ‰ ìš”ì•½]: 
{pine_summary_text}

[NER ì •ë³´]:
{ner_text}
    """

    return context.strip()

async def rag_pipeline(session_id: str, user_input: str, stream: bool = False):
    """
    ë¹„ë™ê¸° ìµœì í™”ëœ RAG ê¸°ë°˜ ì±—ë´‡ íŒŒì´í”„ë¼ì¸ (Streaming ì§€ì›)
    """
    context = await process_user_input(session_id, user_input)

    if stream:
        return response_generator(session_id, user_input, context)

    chat_prompt = make_prompt_chat(context, user_input)
    print(chat_prompt)
    llm_answer = await call_4o_mini(chat_prompt, max_tokens=256, stream=False)

    save_response_task = asyncio.create_task(save_message(session_id, "assistant", llm_answer))

    # ğŸ”¥ ì±—ë´‡ ì‘ë‹µ ì €ì¥ ì™„ë£Œ ë³´ì¥
    await save_response_task

    return llm_answer
